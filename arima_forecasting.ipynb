{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arima Modelling on BQML for Demand Forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading necessary libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error,r2_score\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import numpy as papermill\n",
    "from google.cloud import bigquery\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "client = bigquery.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for first time install pandas_gbq to read data from BQ to a pandas dataframe via pandas.from_gbq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas_gbq\n",
    "!pip install google-cloud-bigquery-storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = ''\n",
    "DATASET_NAME = '' # BQ dataset that has the Data Table and will store the tained Model\n",
    "MODEL_NAME = '' # Name name ofg the model we are going to train\n",
    "TABLE_NAME = '' # BQ Table name with the data\n",
    "TRAIN_UNTIL_DATETIME = '2019-07-21' # The date up to wich the Arima Model will be trained.\n",
    "FORECAST_HORIZON = 14 # Number of dates in the future the model will forecast - Used in Forecasting, not in training\n",
    "\n",
    "TIME_SERIES_ID_COLUMN = '' # Table column or the forecast unit - defining this builds a timeseries model for each ID column. i.e a forecast per SKU\n",
    "TIME_SERIES_DATA_COLUMN = '' # Table column of the attribute we want to be able forecast \n",
    "TIME_SERIES_TIMESTAMP_COLUMN ='' # Table column that maps to timeseries timestamp \n",
    "HOLIDAY_REGION = 'GB'   # Marks public holidays in the arima model\n",
    "\n",
    "RESULTS_METRIC = 'mape' # smape, mape, rmse or mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Arima model up to a specific date "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following query creates a model big query DATASET_NAME.MODEL_NAME\n",
    "using data from DATASET_NAME.TABLE_NAME until TRAIN_UNTIL_DATETIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_forecast_build_model = \"\"\"\n",
    "CREATE OR REPLACE MODEL\n",
    "  `{project}.{dataset}.{model}` OPTIONS(model_type='ARIMA',\n",
    "    holiday_region='{holiday}',\n",
    "    time_series_id_col='{ts_id_col}',\n",
    "    time_series_data_col='{ts_data_col}',\n",
    "    time_series_timestamp_col='{ts_timestamp_col}') AS\n",
    "SELECT\n",
    "  {ts_id_col},\n",
    "  {ts_data_col},\n",
    "  TIMESTAMP({ts_timestamp_col}) as {ts_timestamp_col}\n",
    "FROM\n",
    "  `{project}.{dataset}.{table}`\n",
    "WHERE\n",
    "  {ts_timestamp_col}<='{train_until}'\n",
    "\"\"\".format(project=PROJECT_ID,\n",
    "           dataset = DATASET_NAME, \n",
    "           model=MODEL_NAME, \n",
    "           table=TABLE_NAME, \n",
    "           holiday=HOLIDAY_REGION,\n",
    "           ts_id_col=TIME_SERIES_ID_COLUMN, \n",
    "           ts_data_col=TIME_SERIES_DATA_COLUMN, \n",
    "           ts_timestamp_col=TIME_SERIES_TIMESTAMP_COLUMN,\n",
    "           train_until=TRAIN_UNTIL_DATETIME)\n",
    "\n",
    "\n",
    "query_job = client.query(sql_forecast_build_model)\n",
    "query_job.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sql_forecast_build_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forecast using the train model X datapoints in the future"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used the trained model DATASET_NAME.MODEL_NAME to forecast FORECAST_HORIZON (days) in the future\n",
    "We then join the forcaset with the actual data DATASET_NAME.TABLE_NAME  in order to validate the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_forecast_horizon = \"\"\"\n",
    "SELECT \n",
    "   fc.* EXCEPT ({ts_id_col}),\n",
    "   t.*\n",
    "FROM\n",
    "  ML.FORECAST(MODEL `{project}.{dataset}.{model}`,\n",
    "  STRUCT({forecast_horizon} AS horizon)) AS fc\n",
    "LEFT JOIN (\n",
    "  SELECT\n",
    "    *\n",
    "  FROM\n",
    "    `{project}.{dataset}.{table}`) AS t\n",
    "ON\n",
    "  CAST({ts_timestamp_col} AS TIMESTAMP) = fc.forecast_timestamp\n",
    "  AND t.{ts_id_col}=fc.{ts_id_col}\n",
    "\"\"\".format( project=PROJECT_ID,\n",
    "            dataset = DATASET_NAME, \n",
    "           model=MODEL_NAME, \n",
    "           table=TABLE_NAME, \n",
    "           forecast_horizon=FORECAST_HORIZON, \n",
    "           ts_timestamp_col=TIME_SERIES_TIMESTAMP_COLUMN,\n",
    "           ts_id_col=TIME_SERIES_ID_COLUMN,\n",
    "          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas .read_gbq opperator is used to load the query results into a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sql_forecast_horizon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast = pd.read_gbq(sql_forecast_horizon, dialect='standard', use_bqstorage_api=True)\n",
    "forecast.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast = forecast.dropna()\n",
    "forecast.index = forecast['forecast_timestamp']\n",
    "id_list = forecast[TIME_SERIES_ID_COLUMN].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate MAPE\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "# Function to calculate Symmetric MAPE - This solves issue with items that are sold \n",
    "# is small volumes skewing the results\n",
    "def smape(y_true, y_pred):\n",
    "    out = 0\n",
    "    for i in range(y_true.shape[0]):\n",
    "        a = y_true[i]\n",
    "        b = y_pred[i]\n",
    "        c = a+b\n",
    "        if c == 0:\n",
    "            continue\n",
    "        out += math.fabs(a - b) / c\n",
    "    out *= (200.0 / y_true.shape[0])\n",
    "    if out<0:\n",
    "        return 100\n",
    "    return out\n",
    "\n",
    "# function to compute all evaluations metrics fiven actual and predictions\n",
    "def compute_metrics(x):\n",
    "    result = {\n",
    "        'mae': mean_absolute_error(x[TIME_SERIES_DATA_COLUMN], x['forecast_value']), \n",
    "        'smape': smape(x[TIME_SERIES_DATA_COLUMN], x['forecast_value']), \n",
    "        'mape': mean_absolute_percentage_error(x[TIME_SERIES_DATA_COLUMN], x['forecast_value']), \n",
    "        'rmse': math.sqrt(mean_squared_error(x[TIME_SERIES_DATA_COLUMN], x['forecast_value']))}\n",
    "    return pd.Series(result)\n",
    "\n",
    "\n",
    "# Used to plot a list of items - actual and forecast\n",
    "def plot_items(forecast, item_lst):\n",
    "    row = 0\n",
    "    col = 0\n",
    "    columns_total = 3\n",
    "    rows_total = math.ceil(len(item_lst)/columns_total)\n",
    "    fig, ax =plt.subplots(rows_total,columns_total, figsize=(columns_total*8,rows_total*7))\n",
    "    for i in item_lst:\n",
    "        df = forecast[forecast[TIME_SERIES_ID_COLUMN] == i]\n",
    "        sns.lineplot(x=TIME_SERIES_TIMESTAMP_COLUMN, y=TIME_SERIES_DATA_COLUMN,marker='o', color='deepskyblue', data=df,label=\"actual\", linestyle=\"-\", ax=ax[row,col%3]).set_title(\"Forecast for ts id: \"+i)\n",
    "        sns.lineplot(x=TIME_SERIES_TIMESTAMP_COLUMN, y=\"forecast_value\",marker='o', color='mediumvioletred',ci=95, data=df,label=\"forecast\", ax=ax[row,col%3])\n",
    "        sns.lineplot(x=TIME_SERIES_TIMESTAMP_COLUMN, y=\"confidence_interval_upper_bound\", color='pink', data=df, ax=ax[row,col%3])\n",
    "        sns.lineplot(x=TIME_SERIES_TIMESTAMP_COLUMN, y=\"confidence_interval_lower_bound\", color='pink', data=df, ax=ax[row,col%3])\n",
    "        col+=1\n",
    "        if(col%3==0):\n",
    "            row+=1\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the error metrics Forecast vs Actual\n",
    "We base our experiment on smape as it is the reasonable option from the available metrics. \n",
    "This is because different time series have different sale quantiti scale (tens and hundreds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = forecast.groupby(TIME_SERIES_ID_COLUMN).apply(compute_metrics)\n",
    "result= result.reset_index().sort_values(by=[RESULTS_METRIC])\n",
    "result= result.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "print(' SMAPE | ID Count')\n",
    "print('-------|-----------')\n",
    "print('<10%   |  ',result[result[RESULTS_METRIC]<=10].count()[RESULTS_METRIC])\n",
    "print('<20%   |  ',result[result[RESULTS_METRIC]<=20].count()[RESULTS_METRIC])\n",
    "print('<30%   |  ',result[result[RESULTS_METRIC]<=30].count()[RESULTS_METRIC])\n",
    "print('<40%   |  ',result[result[RESULTS_METRIC]<=40].count()[RESULTS_METRIC])\n",
    "print('<50%   |  ',result[result[RESULTS_METRIC]<=50].count()[RESULTS_METRIC])\n",
    "print('>50%   |  ',result[result[RESULTS_METRIC]>50].count()[RESULTS_METRIC])\n",
    "\n",
    "\n",
    "print(\"\\n\\n All metrics\")\n",
    "result.mean()[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This is how each threashold of MAPE can be interpreted <\n",
    "<img src=\"mape-meaning.png\" width=400 style=\"float:left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pick the best and worst 20 items to show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = forecast.groupby(TIME_SERIES_ID_COLUMN).apply(compute_metrics)\n",
    "result= result.reset_index().sort_values(by=[RESULTS_METRIC])\n",
    "worst = result[-20:]\n",
    "id_list_worst = worst[TIME_SERIES_ID_COLUMN].unique().tolist()\n",
    "best = result[:20]\n",
    "id_list_best = best[TIME_SERIES_ID_COLUMN].unique().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Errors and Forecasts of the Most Accurate Time Series\n",
    "<hr />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25, 4))\n",
    "sns.barplot(x=TIME_SERIES_ID_COLUMN,y=RESULTS_METRIC, data=best).set_title('Most Accurate Predictions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_items(forecast, id_list_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Errors and Forecasts of inacurate Time Series\n",
    "<hr />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25, 4))\n",
    "sns.barplot(x=TIME_SERIES_ID_COLUMN,y='smape', data=worst).set_title('Worst Predictions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_items(forecast, id_list_worst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecasts for all the Time Series\n",
    "<hr />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_items(forecast, id_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
